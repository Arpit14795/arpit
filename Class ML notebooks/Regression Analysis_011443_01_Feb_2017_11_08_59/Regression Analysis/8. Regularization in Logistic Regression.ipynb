{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Classification \n",
    "\n",
    "- Wine dataset from the UCI Machine Learning Repository: [data](http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data), [data dictionary](http://archive.ics.uci.edu/ml/datasets/Wine)\n",
    "- **Goal:** Predict the origin of wine using chemical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare the wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the dataset\n",
    "import pandas as pd\n",
    "url = './Datasets/wine.data'\n",
    "wine = pd.read_csv(url, header=None)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the response variable\n",
    "wine[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = wine.drop(0, axis=1)\n",
    "y = wine[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression (unregularized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.99124151e-01   7.19279747e-01   8.37693694e-01  -6.15868229e-01\n",
      "   -3.70377994e-02  -2.82463938e-03   1.16591034e+00   5.50062272e-02\n",
      "   -3.01116872e-01  -1.99445473e-01  -9.27764817e-02   9.50749025e-01\n",
      "    1.62914206e-02]\n",
      " [  9.25208053e-01  -1.26103740e+00  -8.33651892e-01   2.26252556e-01\n",
      "    2.04570203e-02   3.54760905e-01   5.13094123e-01   1.77967019e-01\n",
      "    7.92779927e-01  -1.69458682e+00   5.05970942e-01  -3.15504616e-01\n",
      "   -1.38557568e-02]\n",
      " [ -3.48621049e-01   7.05375606e-01   1.11108903e-01   2.02375183e-01\n",
      "   -1.34734683e-02  -6.06889861e-01  -1.85854093e+00  -3.86951442e-02\n",
      "   -7.05962480e-01   1.08803431e+00  -3.93735372e-01  -9.41034620e-01\n",
      "    1.02444278e-03]]\n"
     ]
    }
   ],
   "source": [
    "# examine the coefficients\n",
    "print (logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.18229062e-03   1.38301949e-02   9.81987514e-01]\n",
      " [  3.84533237e-05   9.98810545e-01   1.15100193e-03]\n",
      " [  9.85324034e-01   1.30108815e-02   1.66508475e-03]\n",
      " [  1.71289398e-02   9.81687969e-01   1.18309145e-03]\n",
      " [  9.88618919e-01   9.93735465e-06   1.13711441e-02]\n",
      " [  2.09961449e-03   2.82895116e-02   9.69610874e-01]\n",
      " [  7.79537995e-02   8.22834161e-01   9.92120391e-02]\n",
      " [  9.98943529e-01   3.24740043e-07   1.05614645e-03]\n",
      " [  5.93224358e-04   1.27953805e-03   9.98127238e-01]\n",
      " [  3.22030032e-04   9.67960020e-01   3.17179503e-02]\n",
      " [  9.92198282e-01   3.92162652e-04   7.40955538e-03]\n",
      " [  1.65750500e-01   8.28262756e-01   5.98674422e-03]\n",
      " [  1.90619682e-04   9.99075617e-01   7.33763075e-04]\n",
      " [  9.98316173e-01   1.36901471e-03   3.14811982e-04]\n",
      " [  1.56559131e-02   9.83714953e-01   6.29133867e-04]\n",
      " [  3.77712021e-04   9.94445307e-01   5.17698120e-03]\n",
      " [  5.03260379e-07   4.13444103e-01   5.86555394e-01]\n",
      " [  9.28367834e-01   6.90614123e-02   2.57075413e-03]\n",
      " [  1.30362752e-04   9.91327888e-01   8.54174910e-03]\n",
      " [  9.83158684e-01   1.39248833e-06   1.68399234e-02]\n",
      " [  9.97671315e-01   2.05162749e-04   2.12352271e-03]\n",
      " [  3.84081756e-04   9.98650842e-01   9.65075829e-04]\n",
      " [  1.94008986e-03   8.31912192e-01   1.66147718e-01]\n",
      " [  1.46797522e-02   9.84152394e-01   1.16785344e-03]\n",
      " [  9.01875622e-01   9.73942891e-02   7.30089056e-04]\n",
      " [  4.17916903e-04   6.26216516e-02   9.36960431e-01]\n",
      " [  9.92503284e-01   6.71288398e-03   7.83831625e-04]\n",
      " [  9.84245132e-01   1.43116891e-02   1.44317911e-03]\n",
      " [  9.91272455e-01   2.13327497e-04   8.51421748e-03]\n",
      " [  4.02452181e-03   9.67672873e-05   9.95878711e-01]\n",
      " [  1.46894011e-02   9.84965158e-01   3.45441300e-04]\n",
      " [  8.76386862e-05   4.73245694e-05   9.99865037e-01]\n",
      " [  2.03384602e-05   1.36874326e-04   9.99842787e-01]\n",
      " [  9.97218346e-01   4.00462716e-06   2.77764890e-03]\n",
      " [  1.78203047e-01   8.20800131e-01   9.96822099e-04]\n",
      " [  1.76733636e-03   9.96689509e-01   1.54315473e-03]\n",
      " [  1.70422452e-04   9.29207369e-01   7.06222088e-02]\n",
      " [  3.25339807e-01   6.72255462e-01   2.40473082e-03]\n",
      " [  3.64186172e-04   9.97083869e-01   2.55194481e-03]\n",
      " [  9.89123158e-01   2.78685559e-03   8.08998680e-03]\n",
      " [  9.94756597e-01   2.00334031e-03   3.24006318e-03]\n",
      " [  5.05544041e-02   9.40307134e-01   9.13846202e-03]\n",
      " [  1.44950141e-04   1.29589785e-02   9.86896071e-01]\n",
      " [  9.71438324e-01   2.78666792e-02   6.94996381e-04]\n",
      " [  9.90997200e-01   7.23069998e-03   1.77209985e-03]]\n"
     ]
    }
   ],
   "source": [
    "# generate predicted probabilities\n",
    "y_pred_prob = logreg.predict_proba(X_test)\n",
    "print (y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125095797474\n"
     ]
    }
   ],
   "source": [
    "# calculate log loss\n",
    "from sklearn import metrics\n",
    "print (metrics.log_loss(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression (regularized)\n",
    "\n",
    "- [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) documentation\n",
    "- **C:** must be positive, decrease for more regularization\n",
    "- **penalty:** l1 (lasso) or l2 (ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize X_train and X_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21044295  0.          0.          0.          0.          0.\n",
      "   0.48771781  0.          0.          0.          0.          0.15291818\n",
      "   1.47735975]\n",
      " [-0.65721045 -0.05610412 -0.11396509  0.          0.          0.          0.\n",
      "   0.          0.         -0.73818854  0.24416656  0.         -0.63410758]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "  -0.84110528  0.          0.          0.61503491 -0.49042752 -0.30554287\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# try C=0.1 with L1 penalty\n",
    "logreg = LogisticRegression(C=0.1, penalty='l1')\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "print (logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate predicted probabilities and calculate log loss\n",
    "y_pred_prob = logreg.predict_proba(X_test_scaled)\n",
    "print (metrics.log_loss(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.59163934  0.06886667  0.33592964 -0.49616684  0.111539    0.21570086\n",
      "   0.40524509 -0.15526139 -0.02534651  0.05399014  0.14877346  0.42327938\n",
      "   0.89815007]\n",
      " [-0.73545676 -0.32942948 -0.47995296  0.294866   -0.1500246   0.04264373\n",
      "   0.14500586  0.07250763  0.17409795 -0.70726652  0.4128986   0.09997212\n",
      "  -0.81284365]\n",
      " [ 0.20136567  0.30989025  0.15977925  0.18867218  0.04204443 -0.27108109\n",
      "  -0.55886639  0.07486943 -0.17471153  0.68266464 -0.52385748 -0.49566967\n",
      "  -0.02565631]]\n"
     ]
    }
   ],
   "source": [
    "# try C=0.1 with L2 penalty\n",
    "logreg = LogisticRegression(C=0.1, penalty='l2')\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "print (logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate predicted probabilities and calculate log loss\n",
    "y_pred_prob = logreg.predict_proba(X_test_scaled)\n",
    "print (metrics.log_loss(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline of StandardScaler and LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# grid search for best combination of C and penalty\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "C_range = 10.**np.arange(-2, 3)\n",
    "penalty_options = ['l1', 'l2']\n",
    "param_grid = dict(logisticregression__C=C_range, logisticregression__penalty=penalty_options)\n",
    "grid = GridSearchCV(pipe, param_grid, cv=10, scoring='log_loss')\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print all log loss scores\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing regularized linear models with unregularized linear models\n",
    "\n",
    "**Advantages of regularized linear models:**\n",
    "\n",
    "- Better performance\n",
    "- L1 regularization performs automatic feature selection\n",
    "- Useful for high-dimensional problems (p > n)\n",
    "\n",
    "**Disadvantages of regularized linear models:**\n",
    "\n",
    "- Tuning is required\n",
    "- Feature scaling is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
